{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "NUM_SPLITS = 10\n",
    "\n",
    "trn_splits = [None] * NUM_SPLITS\n",
    "tst_splits = [None] * NUM_SPLITS\n",
    "    \n",
    "for spli in range(NUM_SPLITS):  \n",
    "    trn_splits[spli] = pd.read_csv('data/prepared/%d.csv' % spli, sep=';')\n",
    "    tst_splits[spli] = pd.read_csv('data/prepared_test/%d.csv' % spli, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Gradient Boosting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run algorithm\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0\n",
      "Split 0: Best results with depth=5, learning rate=0.70 and 10 estimators, with accuracy=0.87\n",
      "Split 1\n",
      "Split 1: Best results with depth=5, learning rate=0.70 and 150 estimators, with accuracy=0.83\n",
      "Split 2\n",
      "Split 2: Best results with depth=5, learning rate=0.70 and 5 estimators, with accuracy=0.87\n",
      "Split 3\n",
      "Split 3: Best results with depth=5, learning rate=0.50 and 300 estimators, with accuracy=0.90\n",
      "Split 4\n",
      "Split 4: Best results with depth=5, learning rate=0.50 and 25 estimators, with accuracy=0.93\n",
      "Split 5\n",
      "Split 5: Best results with depth=5, learning rate=0.30 and 10 estimators, with accuracy=0.93\n",
      "Split 6\n",
      "Split 6: Best results with depth=5, learning rate=0.70 and 5 estimators, with accuracy=0.87\n",
      "Split 7\n",
      "Split 7: Best results with depth=5, learning rate=0.10 and 25 estimators, with accuracy=0.90\n",
      "Split 8\n",
      "Split 8: Best results with depth=10, learning rate=0.10 and 25 estimators, with accuracy=0.97\n",
      "Split 9\n",
      "Split 9: Best results with depth=5, learning rate=0.70 and 50 estimators, with accuracy=0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import ds_functions as ds\n",
    "\n",
    "labels = [False, True]\n",
    "target = 'DEATH_EVENT'\n",
    "cols = len(max_depths)\n",
    "\n",
    "n_estimators = [5, 10, 25, 50, 75, 100, 150, 200, 250, 300]\n",
    "max_depths = [5, 10, 25]\n",
    "learning_rate = [.1, .3, .5, .7, .9]\n",
    "\n",
    "best_trees = []\n",
    "bests = []\n",
    "accuracies = [[] for _ in range(len(max_depths))]\n",
    "\n",
    "trnY_list = []\n",
    "trnX_list = []\n",
    "tstY_list = []\n",
    "tstX_list = []\n",
    "\n",
    "\n",
    "for spli in range(NUM_SPLITS):\n",
    "    print(\"Split %d\" % spli)\n",
    "    \n",
    "    trn_split = trn_splits[spli]\n",
    "    tst_split = tst_splits[spli]   \n",
    "\n",
    "    trnY = trn_split.pop(target).values\n",
    "    trnX = trn_split.values\n",
    "    tstY = tst_split.pop(target).values\n",
    "    tstX = tst_split.values\n",
    "    \n",
    "    trnY_list.append(trnY)\n",
    "    trnX_list.append(trnX)\n",
    "    tstY_list.append(tstY)\n",
    "    tstX_list.append(tstX)\n",
    "    \n",
    "    \n",
    "    best = ('', 0, 0)\n",
    "    last_best = 0\n",
    "    best_tree = None\n",
    "\n",
    "    \n",
    "    for k in range(cols):\n",
    "        d = max_depths[k]\n",
    "        values = {}\n",
    "        for lr in learning_rate:\n",
    "            yvalues = []\n",
    "            for n in n_estimators:\n",
    "                gb = GradientBoostingClassifier(n_estimators=n, max_depth=d, learning_rate=lr)\n",
    "                gb.fit(trnX, trnY)\n",
    "                prdY = gb.predict(tstX)\n",
    "                yvalues.append(metrics.accuracy_score(tstY, prdY))\n",
    "                if yvalues[-1] > last_best:\n",
    "                    best = (d, lr, n)\n",
    "                    last_best = yvalues[-1]\n",
    "                    best_tree = gb\n",
    "            values[lr] = yvalues\n",
    "        \n",
    "        accuracies[k].append(values)\n",
    "    \n",
    "    best_trees.append(best_tree)\n",
    "    bests.append(best)\n",
    "    \n",
    "    print('Best results with depth=%d, learning rate=%1.2f and %d estimators, with accuracy=%1.2f' %\n",
    "          (*best, last_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import ds_functions as ds\n",
    "\n",
    "labels = [False, True]\n",
    "target = 'DEATH_EVENT'\n",
    "cols = len(max_depths)\n",
    "\n",
    "#min_impurity_decrease = [0.025, 0.01, 0.005, 0.0025, 0.001]\n",
    "#max_depths = [2, 5, 10, 15, 20, 25]\n",
    "#criteria = ['entropy', 'gini']\n",
    "n_estimators = [5, 10, 25, 50, 75, 100, 150, 200, 250, 300]\n",
    "max_depths = [5, 10, 25]\n",
    "learning_rate = [.1, .3, .5, .7, .9]\n",
    "\n",
    "best = ('',  0, 0.0) # (criteria, max depth, min impurity decrease)\n",
    "#best_tree = None\n",
    "last_best = 0 # accuracy\n",
    "#best_split = None\n",
    "#best_spli = 0\n",
    "\n",
    "split_best = [('',  0, 0.0)] * NUM_SPLITS\n",
    "split_best_tree = [None] * NUM_SPLITS\n",
    "split_last_best = [0] * NUM_SPLITS\n",
    "\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 4), squeeze=False)\n",
    "for k in range(len(criteria)):\n",
    "    f = criteria[k]\n",
    "    values = {}\n",
    "    for d in max_depths:\n",
    "        values[d] = []\n",
    "        for i in range(len(min_impurity_decrease)):\n",
    "            values[d].append(0)\n",
    "    for spli in range(NUM_SPLITS):\n",
    "        split = splits[spli]\n",
    "        for d in max_depths:\n",
    "            yvalues = []\n",
    "            for imp in min_impurity_decrease:\n",
    "                tree = DecisionTreeClassifier(max_depth=d, criterion=f, min_impurity_decrease=imp)\n",
    "                tree.fit(split['X_train'], split['y_train'])\n",
    "                split['prdY'] = tree.predict(split['X_test'])\n",
    "                yvalues.append(metrics.accuracy_score(split['y_test'], split['prdY']))\n",
    "                # Check if accuracy is better than best overall\n",
    "                if yvalues[-1] > last_best:\n",
    "                    best = (f, d, imp)\n",
    "                    last_best = yvalues[-1]\n",
    "                    best_tree = tree\n",
    "                    best_split = split\n",
    "                    best_spli = spli\n",
    "                # Check if accuracy is better than best in current split\n",
    "                if yvalues[-1] > split_last_best[spli]:\n",
    "                    split_best[spli] = (f, d, imp)\n",
    "                    split_last_best[spli] = yvalues[-1]\n",
    "                    split_best_tree[spli] = tree\n",
    "            # Increment total accuracy for current (max_depth, min_impurity decrease)\n",
    "            for i in range(len(yvalues)):\n",
    "                values[d][i] += yvalues[i]\n",
    "    # Normalize\n",
    "    for v in values:\n",
    "        for i in range(len(values[v])):\n",
    "            values[v][i] /= NUM_SPLITS\n",
    "            \n",
    "    ds.multiple_line_chart(min_impurity_decrease, values, ax=axs[0, k], title='Decision Trees with %s criteria'%f,\n",
    "                           xlabel='min_impurity_decrease', ylabel='accuracy', percentage=True)\n",
    "plt.show()\n",
    "print('Best results achieved in split %d with %s criteria, depth=%d and min_impurity_decrease=%f ==> accuracy=%f'%(best_spli, best[0], best[1], best[2], last_best))\n",
    "\n",
    "print('Best results per split:')\n",
    "for i in range(len(splits)):\n",
    "    print('\\tSplit %d: %s criteria, depth=%d and min_impurity_decrease=%f ==> accuracy=%f' % (i, *split_best[i], split_last_best[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracies[0][0][0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracies = [{lr: 0 for lr in learning_rate} for _ in cols]\n",
    "\n",
    "for k in range(cols):\n",
    "    for spli in range(NUM_SPLITS):\n",
    "        for \n",
    "    total_accuracies\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, cols, figsize=(cols*ds.HEIGHT, ds.HEIGHT), squeeze=False)\n",
    "\n",
    "for k in range(cols):   \n",
    "    ds.multiple_line_chart(n_estimators, values, ax=axs[0, k], title='Gradient Boorsting with max_depth=%d'%d,\n",
    "                               xlabel='nr estimators', ylabel='accuracy', percentage=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 2691]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b613fdbb9a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprd_test_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspli\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtstX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspli\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_evaluation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnY_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd_train_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtstY_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd_test_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshowXTickLabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/Filipe/Documents/GitHub/ds_project/utils/ds_functions.py\u001b[0m in \u001b[0;36mplot_evaluation_results\u001b[0;34m(labels, trn_y, prd_trn, tst_y, prd_tst, showXTickLabels)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_evaluation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd_tst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshowXTickLabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mcnf_mtx_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mtn_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnf_mtx_trn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mcnf_mtx_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd_tst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 2691]"
     ]
    }
   ],
   "source": [
    "prd_train_all = []\n",
    "prd_test_all = []\n",
    "\n",
    "for spli in range(NUM_SPLITS):\n",
    "    prd_train_all.extend(best_trees[spli].predict(trnX_list[spli]))\n",
    "    prd_test_all.extend(best_trees[spli].predict(tstX_list[spli]))\n",
    "    \n",
    "ds.plot_evaluation_results(labels, trnY_list, prd_train_all, tstY_list, prd_test_all, showXTickLabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spli in range(NUM_SPLITS):\n",
    "    d = split_best[spli][1]\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(1, len(criteria), figsize=(16, 4), squeeze=False)\n",
    "    for k in range(len(criteria)):\n",
    "        f = criteria[k]\n",
    "        values = {}\n",
    "        yvalues = []\n",
    "        yvalues_train = []\n",
    "        for imp in min_impurity_decrease:\n",
    "            tree = DecisionTreeClassifier(max_depth=d, criterion=f, min_impurity_decrease=imp)\n",
    "            tree.fit(trnX_list[spli], trnY_list[spli])\n",
    "            prdY = tree.predict(tstX_list[spli])\n",
    "            prdY_train = tree.predict(trnX_list[spli])\n",
    "            yvalues.append(metrics.accuracy_score(tstY_list[spli], prdY))\n",
    "            yvalues_train.append(metrics.accuracy_score(trnY_list[spli], prdY_train))\n",
    "        values['test'] = yvalues\n",
    "        values['train'] = yvalues_train\n",
    "        ds.multiple_line_chart(min_impurity_decrease, values, ax=axs[0, k], title='Decision Trees with %s criteria (split %d)'%(f, spli),\n",
    "                           xlabel='min_impurity_decrease', ylabel='accuracy', percentage=True)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
