{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. KNN\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../utils')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_functions as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataTrain: pd.DataFrame = pd.read_csv('data/prepared/data.csv', sep=';')\n",
    "dataTest: pd.DataFrame = pd.read_csv('data/prepared_test/data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import ds_functions as ds\n",
    "\n",
    "trnY: np.ndarray = dataTrain.pop('exp').values\n",
    "trnX: np.ndarray = dataTrain.values\n",
    "tstY: np.ndarray = dataTest.pop('exp').values\n",
    "tstX: np.ndarray = dataTest.values\n",
    "    \n",
    "labels = pd.unique(trnY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "nvalues = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "dist = ['manhattan', 'euclidean', 'chebyshev']\n",
    "values = {}\n",
    "best = (0, '')\n",
    "last_best = 0\n",
    "for d in dist:\n",
    "    yvalues = []\n",
    "    for n in nvalues:\n",
    "        knn = KNeighborsClassifier(n_neighbors=n, metric=d)\n",
    "        knn.fit(trnX, trnY)\n",
    "        prdY = knn.predict(tstX)\n",
    "        yvalues.append(metrics.accuracy_score(tstY, prdY))\n",
    "        if yvalues[-1] > last_best:\n",
    "            best = (n, d)\n",
    "            last_best = yvalues[-1]\n",
    "    values[d] = yvalues\n",
    "\n",
    "plt.figure()\n",
    "ds.multiple_line_chart(nvalues, values, title='KNN variants', xlabel='n', ylabel='accuracy', percentage=True)\n",
    "plt.show()\n",
    "print('Best results with %d neighbors and %s'%(best[0], best[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = knn = KNeighborsClassifier(n_neighbors=best[0], metric=best[1])\n",
    "clf.fit(trnX, trnY)\n",
    "prd_trn = clf.predict(trnX)\n",
    "prd_tst = clf.predict(tstX)\n",
    "ds.plot_evaluation_results(labels, trnY, prd_trn, tstY, prd_tst, showXTickLabels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "---\n",
    "\n",
    "***How do models improve with the increase of neighbors?***\n",
    "\n",
    "\n",
    "\n",
    "***How does performance changes with different distance measures?***\n",
    "\n",
    "\n",
    "\n",
    "***What is the best parametrisation (number of neighbors and distance measure)?***\n",
    "\n",
    "\n",
    "\n",
    "***Is the accuracy achieved good enough?***\n",
    "\n",
    "\n",
    "\n",
    "***What is the largest kind of errors?***\n",
    "\n",
    "\n",
    "\n",
    "***Is it possible to identify overfitting?***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
